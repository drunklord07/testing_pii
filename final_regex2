import os
import re
import sys
import json
import shutil
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import List, Tuple
from tqdm import tqdm
from datetime import datetime

# =================== CONFIGURATION =================== #
input_dir = Path("new_logs")  # ðŸ”§ SET your input folder name here
output_dir = Path("output")
report_path = Path("summary_report.txt")
# ===================================================== #

# Aadhaar Verhoeff checksum tables
verhoeff_d = [
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
    [1, 2, 3, 4, 0, 6, 7, 8, 9, 5],
    [2, 3, 4, 0, 1, 7, 8, 9, 5, 6],
    [3, 4, 0, 1, 2, 8, 9, 5, 6, 7],
    [4, 0, 1, 2, 3, 9, 5, 6, 7, 8],
    [5, 9, 8, 7, 6, 0, 4, 3, 2, 1],
    [6, 5, 9, 8, 7, 1, 0, 4, 3, 2],
    [7, 6, 5, 9, 8, 2, 1, 0, 4, 3],
    [8, 7, 6, 5, 9, 3, 2, 1, 0, 4],
    [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
]
verhoeff_p = [
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
    [1, 5, 7, 6, 2, 8, 3, 0, 9, 4],
    [5, 8, 0, 3, 7, 9, 6, 1, 4, 2],
    [8, 9, 1, 6, 0, 4, 3, 5, 2, 7],
    [9, 4, 5, 3, 1, 2, 6, 8, 7, 0],
    [4, 2, 8, 6, 5, 7, 3, 9, 0, 1],
    [2, 7, 9, 3, 8, 0, 6, 4, 1, 5],
    [7, 0, 4, 6, 9, 1, 3, 2, 5, 8]
]

def is_valid_aadhaar(num: str) -> bool:
    c = 0
    try:
        for i, item in enumerate(reversed(num)):
            c = verhoeff_d[c][verhoeff_p[i % 8][int(item)]]
        return c == 0
    except:
        return False

# PII Patterns
PII_PATTERNS = {
    "AADHAAR_REGEX": re.compile(r'(?<!\d)(\d{12})(?!\d)'),
    "DL_REGEX": re.compile(r'(?<!\w)[A-Z]{2}[0-9]{2}[-\s]?[0-9]{4}[0-9]{7}(?!\w)', re.IGNORECASE),
    "GSTIN_REGEX": re.compile(r'(?<!\w)[0-9]{2}[A-Z]{5}[0-9]{4}[A-Z][A-Z0-9]Z[A-Z0-9](?!\w)', re.IGNORECASE),
    "IP_REGEX": re.compile(r'(?<!\d)(?:[0-9]{1,3}\.){3}[0-9]{1,3}(?!\d)'),
    "MAC_REGEX": re.compile(r'(?<![A-Fa-f0-9])(?:[0-9A-Fa-f]{2}[:-]){5}[0-9A-Fa-f]{2}(?![A-Fa-f0-9])'),
    "EMAIL_REGEX": re.compile(r'(?<![\w.])[\w\.-]+@[\w\.-]+\.\w{2,}(?![\w])'),
    "MOBILE_REGEX": re.compile(r'(?<!\d)(?:\+91|91|0)?[6-9][0-9]{9}(?!\d)'),
    "PAN_REGEX": re.compile(r'(?<!\w)[A-Z]{5}[0-9]{4}[A-Z](?!\w)', re.IGNORECASE),
    "UPI_REGEX": re.compile(r'(?<![\w.])[a-zA-Z0-9.\-_]{2,}@[a-zA-Z]{2,}(?![\w])'),
    "VOTERID_REGEX": re.compile(r'(?<!\w)[A-Z]{3}[0-9]{7}(?!\w)', re.IGNORECASE),
    "CARD_REGEX": re.compile(
        r'(?<!\d)('
        r'4[0-9]{12}(?:[0-9]{3})?'
        r'|5[1-5][0-9]{14}'
        r'|2(?:2[2-9][0-9]{12}|[3-6][0-9]{13}|7(?:[01][0-9]{12}|20[0-9]{12}))'
        r'|3[47][0-9]{13}'
        r'|60[0-9]{14}'
        r'|65[0-9]{14}'
        r'|81[0-9]{14}'
        r'|508[0-9][0-9]{12}'
        r')(?!\d)'
    )
}

def extract_matches(line: str) -> List[Tuple[str, str]]:
    matches = []
    for pii_type, pattern in PII_PATTERNS.items():
        for match in pattern.finditer(line):
            val = match.group()
            if pii_type == "AADHAAR_REGEX" and not is_valid_aadhaar(val):
                continue
            matches.append((val, pii_type))
    return matches

def process_file(file_path: Path) -> Tuple[str, int, int, dict, int, int, List[str]]:
    rel_path = file_path.relative_to(input_dir)
    output_file = output_dir / rel_path
    if output_file.exists():  # Resume mode
        return str(rel_path), 0, 0, {k: 0 for k in PII_PATTERNS}, 0, 0, []

    output_file.parent.mkdir(parents=True, exist_ok=True)
    lines_out = []
    stats = {
        "lines_read": 0,
        "lines_written": 0,
        "matches_per_type": {k: 0 for k in PII_PATTERNS},
        "lines_added_due_to_duplicates": 0,
        "lines_skipped_no_match": 0
    }

    blank_file = True
    with file_path.open("r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            line = line.strip()
            if not line: continue
            stats["lines_read"] += 1
            if ";" not in line: continue
            log, path = line.rsplit(";", 1)
            matches = extract_matches(log)
            if not matches:
                stats["lines_skipped_no_match"] += 1
                continue
            for idx, (val, pii_type) in enumerate(matches):
                new_line = f"{log};{path};{val};{pii_type}"
                lines_out.append(new_line)
                stats["matches_per_type"][pii_type] += 1
                if idx > 0:
                    stats["lines_added_due_to_duplicates"] += 1
            stats["lines_written"] += 1
            blank_file = False

    with output_file.open("w", encoding="utf-8") as out:
        for line in lines_out:
            out.write(line + "\n")

    return (
        str(rel_path),
        stats["lines_read"],
        stats["lines_written"],
        stats["matches_per_type"],
        stats["lines_added_due_to_duplicates"],
        stats["lines_skipped_no_match"],
        [] if not blank_file else [str(rel_path)]
    )

def run_pii_extraction(input_dir: Path, output_dir: Path, report_path: Path):
    if output_dir.exists():
        shutil.rmtree(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    files = list(input_dir.rglob("*.txt"))
    summary = {
        "total_files": 0,
        "total_lines_read": 0,
        "total_lines_written": 0,
        "total_lines_added_due_to_duplicates": 0,
        "total_lines_skipped_no_match": 0,
        "matches_per_type": {k: 0 for k in PII_PATTERNS},
        "blank_files": [],
        "errors": []
    }

    max_workers = max(1, os.cpu_count() - 2)
    print(f"[âœ”] Using {max_workers} safe worker threads...\n")

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_file, file): file for file in files}
        for future in tqdm(as_completed(futures), total=len(futures), desc="Processing Files"):
            try:
                file, read, written, matches, added, skipped, blanks = future.result()
                summary["total_files"] += 1
                summary["total_lines_read"] += read
                summary["total_lines_written"] += written
                summary["total_lines_added_due_to_duplicates"] += added
                summary["total_lines_skipped_no_match"] += skipped
                for k in matches:
                    summary["matches_per_type"][k] += matches[k]
                summary["blank_files"].extend(blanks)
            except Exception as e:
                summary["errors"].append(f"{futures[future]}: {str(e)}")

    with report_path.open("w", encoding="utf-8") as rpt:
        rpt.write(f"PII Regex Scan Report - {datetime.now()}\n\n")
        rpt.write(f"Total files scanned: {summary['total_files']}\n")
        rpt.write(f"Total lines scanned: {summary['total_lines_read']}\n")
        rpt.write(f"Total lines written to output: {summary['total_lines_written']}\n")
        rpt.write(f"Lines skipped (no match): {summary['total_lines_skipped_no_match']}\n")
        rpt.write(f"Lines added due to multiple matches: {summary['total_lines_added_due_to_duplicates']}\n")
        rpt.write(f"Final output lines (approx): {summary['total_lines_written'] + summary['total_lines_added_due_to_duplicates']}\n\n")
        rpt.write("Match counts by type:\n")
        for k, v in summary["matches_per_type"].items():
            rpt.write(f"  {k}: {v}\n")
        if summary["blank_files"]:
            rpt.write("\nBlank files:\n")
            for f in summary["blank_files"]:
                rpt.write(f"  {f}\n")
        if summary["errors"]:
            rpt.write("\nErrors:\n")
            for e in summary["errors"]:
                rpt.write(f"  {e}\n")

# âœ… SAFELY ENABLED FOR WINDOWS
if __name__ == "__main__":
    run_pii_extraction(input_dir, output_dir, report_path)
