import os
import re
import sys
from tqdm import tqdm
import concurrent.futures
from functools import lru_cache
from datetime import datetime

# ====== CONFIGURATION ====== #
INPUT_FOLDER = "/your/full/path/to/input_folder"  # ðŸ”§ Replace with your path
OUTPUT_FOLDER = "output_regex"
SUMMARY_FILE = "summary_report.txt"
# =========================== #

os.makedirs(OUTPUT_FOLDER, exist_ok=True)

PII_PATTERNS = {
    "MOBILE_REGEX": re.compile(r'(?<![A-Za-z0-9])(?:\+91|91|0)?[6-9][0-9]{9}(?![A-Za-z0-9])'),
    "AADHAAR_REGEX": re.compile(r'(?<![A-Za-z0-9])(\d{12})(?![A-Za-z0-9])'),
    "PAN_REGEX": re.compile(r'(?<![A-Za-z0-9])[A-Z]{5}[0-9]{4}[A-Z](?![A-Za-z0-9])', re.IGNORECASE),
    "GSTIN_REGEX": re.compile(r'(?<![A-Za-z0-9])[0-9]{2}[A-Z]{5}[0-9]{4}[A-Z][1-9A-Z]Z[0-9A-Z](?![A-Za-z0-9])', re.IGNORECASE),
    "DL_REGEX": re.compile(r'(?<![A-Za-z0-9])[A-Z]{2}[0-9]{2}[0-9]{11}(?![A-Za-z0-9])', re.IGNORECASE),
    "VOTERID_REGEX": re.compile(r'(?<![A-Za-z0-9])[A-Z]{3}[0-9]{7}(?![A-Za-z0-9])', re.IGNORECASE),
    "EMAIL_REGEX": re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,3}', re.IGNORECASE),
    "UPI_REGEX": re.compile(r'[a-zA-Z0-9.\-_]{2,256}@[a-zA-Z]{2,64}'),
    "IP_REGEX": re.compile(r'(?<!\d)(?:[0-9]{1,3}\.){3}[0-9]{1,3}(?!\d)'),
    "MAC_REGEX": re.compile(r'(?<![A-Fa-f0-9])(?:[0-9A-Fa-f]{2}[:-]){5}[0-9A-Fa-f]{2}(?![A-Fa-f0-9])'),
    "CARD_REGEX": re.compile(
        r'(?<!\d)('
        r'4[0-9]{12}(?:[0-9]{3})?'
        r'|5[1-5][0-9]{14}'
        r'|2(?:2[2-9][0-9]{12}|[3-6][0-9]{13}|7(?:[01][0-9]{12}|20[0-9]{12}))'
        r'|3[47][0-9]{13}'
        r'|60[0-9]{14}'
        r'|65[0-9]{14}'
        r'|81[0-9]{14}'
        r'|508[0-9][0-9]{12}'
        r')(?!\d)'
    )
}

summary = {
    "files_scanned": 0,
    "total_lines": 0,
    "total_matches": 0,
    "total_no_match_lines": 0,
    "per_type_counts": {k: 0 for k in PII_PATTERNS},
    "blank_files": [],
    "errors": [],
    "output_lines_written": 0
}

@lru_cache(maxsize=10000)
def is_valid_aadhaar(number):
    def verhoeff_checksum(num):
        mul_table = [
            [0,1,2,3,4,5,6,7,8,9],
            [1,2,3,4,0,6,7,8,9,5],
            [2,3,4,0,1,7,8,9,5,6],
            [3,4,0,1,2,8,9,5,6,7],
            [4,0,1,2,3,9,5,6,7,8],
            [5,9,8,7,6,0,4,3,2,1],
            [6,5,9,8,7,1,0,4,3,2],
            [7,6,5,9,8,2,1,0,4,3],
            [8,7,6,5,9,3,2,1,0,4],
            [9,8,7,6,5,4,3,2,1,0]
        ]
        perm_table = [
            [0,1,2,3,4,5,6,7,8,9],
            [1,5,7,6,2,8,3,0,9,4],
            [5,8,0,3,7,9,6,1,4,2],
            [8,9,1,6,0,4,3,5,2,7],
            [9,4,5,3,1,2,6,8,7,0],
            [4,2,8,6,5,7,3,9,0,1],
            [2,7,9,3,8,0,6,4,1,5],
            [7,0,4,6,9,1,3,2,5,8]
        ]
        inv_table = [0,4,3,2,1,5,6,7,8,9]
        c = 0
        for i, item in enumerate(reversed(num)):
            c = mul_table[c][perm_table[i % 8][int(item)]]
        return inv_table[c]

    return len(number) == 12 and verhoeff_checksum(number) == 0

def extract_matches(line):
    matches = []
    for pii_type, pattern in PII_PATTERNS.items():
        if not pattern.search(line):
            continue
        for match in pattern.finditer(line):
            value = match.group(0)
            if pii_type == "AADHAAR_REGEX" and not is_valid_aadhaar(value):
                continue
            matches.append((value, pii_type))
            summary["per_type_counts"][pii_type] += 1
    return matches

def process_file(file_path):
    local_output = []
    file_name = os.path.basename(file_path)
    output_file = os.path.join(OUTPUT_FOLDER, file_name)
    lines_written = 0
    local_no_match_lines = 0
    local_lines = 0
    try:
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f, \
             open(output_file, "w", encoding="utf-8") as out_f, \
             tqdm(desc=f"Processing {file_name}", unit="lines", position=0, leave=False) as pbar:
            for line in f:
                local_lines += 1
                line = line.rstrip('\n')
                if ';' in line:
                    log_line, path = line.rsplit(';', 1)
                else:
                    log_line, path = line, "UNKNOWN_PATH"
                matches = extract_matches(log_line)
                if matches:
                    for value, pii_type in matches:
                        out_f.write(f"{log_line};{path} {value};{pii_type}\n")
                        lines_written += 1
                else:
                    local_no_match_lines += 1
                pbar.update(1)
    except Exception as e:
        summary["errors"].append(f"{file_name}: {e}")
        return

    summary["files_scanned"] += 1
    summary["total_lines"] += local_lines
    summary["output_lines_written"] += lines_written
    summary["total_no_match_lines"] += local_no_match_lines
    if local_lines == 0 or lines_written == 0:
        summary["blank_files"].append(file_name)

def write_summary():
    with open(SUMMARY_FILE, "w", encoding="utf-8") as f:
        f.write(f"Summary Report - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Input Folder: {INPUT_FOLDER}\n")
        f.write(f"Output Folder: {OUTPUT_FOLDER}\n\n")
        f.write(f"Total Files Scanned: {summary['files_scanned']}\n")
        f.write(f"Total Lines Scanned: {summary['total_lines']}\n")
        f.write(f"Total PII Matches Found: {sum(summary['per_type_counts'].values())}\n")
        f.write(f"Total Output Lines Written: {summary['output_lines_written']}\n")
        f.write(f"Total Lines with NO_MATCH: {summary['total_no_match_lines']}\n\n")
        f.write("PII Type Counts:\n")
        for pii_type, count in summary['per_type_counts'].items():
            f.write(f"- {pii_type}: {count}\n")
        if summary['blank_files']:
            f.write("\nFiles with No Matches or Blank:\n")
            for f_name in summary['blank_files']:
                f.write(f"- {f_name}\n")
        if summary['errors']:
            f.write("\nErrors:\n")
            for err in summary['errors']:
                f.write(f"- {err}\n")

def main():
    all_files = [
        os.path.join(INPUT_FOLDER, f)
        for f in os.listdir(INPUT_FOLDER)
        if f.endswith(".txt") and os.path.isfile(os.path.join(INPUT_FOLDER, f))
    ]
    with concurrent.futures.ProcessPoolExecutor(max_workers=6) as executor:
        executor.map(process_file, all_files)
    write_summary()

if __name__ == "__main__":
    main()
